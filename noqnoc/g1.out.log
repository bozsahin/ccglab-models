===================
I am called as: /Users/bozsahin/myrepos/ccglab/bin/ccglab.nohup.sbcl 4000 64 g1 t 5 0.5 1.2 ouat
            at: Tue Jul 24 13:30:39 +03 2018
Log goes to   : ouat
I will call sbcl as: /usr/local/bin/sbcl --dynamic-space-size 4000
It will call train-nohup-sbcl in /Users/bozsahin/myrepos/ccglab/bin/train-nohup-sbcl.lisp as: (train-nohup-sbcl "g1" 64 t "g1.ind.nohupped.5N.0.5a.1.2c" 5 0.5 1.2)
===================
This is SBCL 1.2.11, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
OOV is reset (OOV errors reported)
All LFs will be shown
*Beamp* = NIL  *Beam-exp* = 0.9
*Beamp* = NIL  *Beam-exp* = 0.9

======================= l o a d i n g =======================================
; loading #P"/Users/bozsahin/myrepos/ccglab-models/noqnoc/g1.ind"

Project [g1] is assumed to consist of
-----------------------------------------------------------------------------
  CCG grammar source : g1.ccg $
    Its token form   : g1.lisptokens $
  Deduction grammar  : g1.ded $ (derived from g1.lisptokens)
  Induction grammar  : g1.ind #
  Supervision source : g1.sup ^
  Model-specific code: g1.lisp ^
   and other model-specific files you may create.
       *CCG-GRAMMAR* : set from g1.ind
  *LEX-RULES-TABLE*  : set from g1.ind
Expected files       : $ for deduction, # for induction, ^ for model development
=============================================================================

Supervision file loaded: g1.sup
Done. use (show-training/save-training) to see/save the results
Evaluation took:
  2.451 seconds of real time
  2.437469 seconds of total run time (2.357911 user, 0.079558 system)
  [ Run times consist of 0.107 seconds GC time, and 2.331 seconds non-GC time. ]
  99.43% CPU
  8 forms interpreted
  5,881,989,768 processor cycles
  1 page fault
  223,929,360 bytes consed
  
The rule set used in the experiment:
To change a switch, use (setf <switchname> <value>)
	      where <value> is T (on) or NIL (off)
	  *f-apply*     T
	  *b-apply*     T
	  *f-comp*      T
	  *b-comp*      T
	  *fx-comp*     T
	  *bx-comp*     T
	  *f-sub*       T
	  *b-sub*       T
	  *fx-sub*      T
	  *bx-sub*      T
          *f-subbar*    NIL
	  *b-subbar*    NIL
	  *fx-subbar*   NIL
	  *bx-subbar*   NIL
	  *f-subcomp*   T
	  *b-subcomp*   T
	  *fx-subcomp*  T
	  *bx-subcomp*  T
          *f2-comp*     T
	  *b2-comp*     T
	  *fx2-comp*    T
	  *bx2-comp*    T
	  *f2-sub*      T
	  *b2-sub*      T
	  *fx2-sub*     T
	  *bx2-sub*     T
	  *f3-comp*     T
	  *b3-comp*     T
	  *fx3-comp*    T
	  *bx3-comp*    T

Training parameters: N = 5 alpha0 = 0.5 c = 1.2 n = 6  *Beamp* = NIL  *Beam-exp* = 0.9

Model parameters before and after training
================================================
key   lex             initial  final    diff 
------------------------------------------------
1     KNOWS             1.0 3.097243  (2.097243)
2     KNOWS             1.0 1.858973  (.8589729)
3     KNOWS             1.0 .3009192  (-.699081)
4     KNOWS             1.0 -.395615  (-1.39561)
5     LOVES             1.0 3.123218  (2.123218)
6     LOVES             1.0  -1.1607  ( -2.1607)
7     JOHN              1.0 2.611841  (1.611841)
8     JOHN              1.0 1.661558  (.6615583)
9     JOHN              1.0 1.916516  (.9165158)
10    JOHN              1.0 .3003718  (-.699628)
11    MARY              1.0 2.348088  (1.348088)
12    MARY              1.0 1.793246  (.7932463)
13    MARY              1.0 2.102374  (1.102374)
14    MARY              1.0 .1457217  (-.854278)
15    JOHN              1.0 -.600183  (-1.60018)
16    JOHN              1.0 .3003718  (-.699628)
17    MARY              1.0 -0.45084  (-1.45084)
18    MARY              1.0 .1457217  (-.854278)
================================================