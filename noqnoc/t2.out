===================
I am called as: /home/cem/ccglab/bin/ccglab.nohup.sbcl 8000 100 g1 t 10 1.0 1.0 t2.out
            at: Tue Jul 24 17:16:06 EEST 2018
Log goes to   : t2.out
I will call sbcl as: /usr/bin/sbcl --dynamic-space-size 8000
It will call train-nohup-sbcl in /home/cem/ccglab/bin/train-nohup-sbcl.lisp as: (train-nohup-sbcl "g1" 100 t "g1.ind.nohupped.10N.1.0a.1.0c" 10 1.0 1.0)
===================
This is SBCL 1.2.15-1.fc23, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
OOV is reset (OOV errors reported)
All LFs will be shown
*Beamp* = NIL  *Beam-exp* = 0.9
*Beamp* = NIL  *Beam-exp* = 0.9

======================= l o a d i n g =======================================
; loading #P"/home/cem/ccglab-models/noqnoc/g1.ind"

Project [g1] is assumed to consist of
-----------------------------------------------------------------------------
  CCG grammar source : g1.ccg $
    Its token form   : g1.lisptokens $
  Deduction grammar  : g1.ded $ (derived from g1.lisptokens)
  Induction grammar  : g1.ind #
  Supervision source : g1.sup ^
  Model-specific code: g1.lisp ^
   and other model-specific files you may create.
       *CCG-GRAMMAR* : set from g1.ind
  *LEX-RULES-TABLE*  : set from g1.ind
Expected files       : $ for deduction, # for induction, ^ for model development
=============================================================================

Supervision file loaded: g1.sup
Done. use (show-training/save-training) to see/save the results
Evaluation took:
  5.627 seconds of real time
  5.609160 seconds of total run time (5.540457 user, 0.068703 system)
  [ Run times consist of 0.057 seconds GC time, and 5.553 seconds non-GC time. ]
  99.68% CPU
  6 forms interpreted
  13,506,930,549 processor cycles
  436,992,880 bytes consed
  
The rule set used in the experiment:
To change a switch, use (setf <switchname> <value>)
	      where <value> is T (on) or NIL (off)
	  *f-apply*     T
	  *b-apply*     T
	  *f-comp*      T
	  *b-comp*      T
	  *fx-comp*     T
	  *bx-comp*     T
	  *f-sub*       T
	  *b-sub*       T
	  *fx-sub*      T
	  *bx-sub*      T
          *f-subbar*    NIL
	  *b-subbar*    NIL
	  *fx-subbar*   NIL
	  *bx-subbar*   NIL
	  *f-subcomp*   T
	  *b-subcomp*   T
	  *fx-subcomp*  T
	  *bx-subcomp*  T
          *f2-comp*     T
	  *b2-comp*     T
	  *fx2-comp*    T
	  *bx2-comp*    T
	  *f2-sub*      T
	  *b2-sub*      T
	  *fx2-sub*     T
	  *bx2-sub*     T
	  *f3-comp*     T
	  *b3-comp*     T
	  *fx3-comp*    T
	  *bx3-comp*    T

Training parameters: N = 10 alpha0 = 1.0 c = 1.0 n = 6  *Beamp* = NIL  *Beam-exp* = 0.9

Model parameters before and after training
================================================
key   lex             initial  final    diff 
------------------------------------------------
1     KNOWS             1.0 7.441595  (6.441595)
2     KNOWS             1.0 3.825647  (2.825647)
3     KNOWS             1.0  -1.1472  ( -2.1472)
4     KNOWS             1.0 -3.37033  (-4.37033)
5     LOVES             1.0 7.043674  (6.043674)
6     LOVES             1.0 -5.15808  (-6.15808)
7     JOHN              1.0 5.554564  (4.554564)
8     JOHN              1.0 2.970176  (1.970176)
9     JOHN              1.0 3.712413  (2.712413)
10    JOHN              1.0 -1.07364  (-2.07364)
11    MARY              1.0 5.097501  (4.097501)
12    MARY              1.0 3.261242  (2.261242)
13    MARY              1.0 4.124776  (3.124776)
14    MARY              1.0 -1.41044  (-2.41044)
15    JOHN              1.0 -3.55847  (-4.55847)
16    JOHN              1.0 -1.07364  (-2.07364)
17    MARY              1.0 -3.38225  (-4.38225)
18    MARY              1.0 -1.41044  (-2.41044)
================================================