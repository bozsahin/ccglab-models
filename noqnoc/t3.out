===================
I am called as: /home/cem/ccglab/bin/ccglab.nohup.sbcl 6000 60 g1 t 3 1.0 1.2 t3.out
            at: Tue Jul 24 17:16:06 EEST 2018
Log goes to   : t3.out
I will call sbcl as: /usr/bin/sbcl --dynamic-space-size 6000
It will call train-nohup-sbcl in /home/cem/ccglab/bin/train-nohup-sbcl.lisp as: (train-nohup-sbcl "g1" 60 t "g1.ind.nohupped.3N.1.0a.1.2c" 3 1.0 1.2)
===================
This is SBCL 1.2.15-1.fc23, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
OOV is reset (OOV errors reported)
All LFs will be shown
*Beamp* = NIL  *Beam-exp* = 0.9
*Beamp* = NIL  *Beam-exp* = 0.9

======================= l o a d i n g =======================================
; loading #P"/home/cem/ccglab-models/noqnoc/g1.ind"

Project [g1] is assumed to consist of
-----------------------------------------------------------------------------
  CCG grammar source : g1.ccg $
    Its token form   : g1.lisptokens $
  Deduction grammar  : g1.ded $ (derived from g1.lisptokens)
  Induction grammar  : g1.ind #
  Supervision source : g1.sup ^
  Model-specific code: g1.lisp ^
   and other model-specific files you may create.
       *CCG-GRAMMAR* : set from g1.ind
  *LEX-RULES-TABLE*  : set from g1.ind
Expected files       : $ for deduction, # for induction, ^ for model development
=============================================================================

Supervision file loaded: g1.sup
Done. use (show-training/save-training) to see/save the results
Evaluation took:
  1.993 seconds of real time
  1.985364 seconds of total run time (1.966338 user, 0.019026 system)
  [ Run times consist of 0.017 seconds GC time, and 1.969 seconds non-GC time. ]
  99.60% CPU
  6 forms interpreted
  4,783,694,814 processor cycles
  139,408,176 bytes consed
  
The rule set used in the experiment:
To change a switch, use (setf <switchname> <value>)
	      where <value> is T (on) or NIL (off)
	  *f-apply*     T
	  *b-apply*     T
	  *f-comp*      T
	  *b-comp*      T
	  *fx-comp*     T
	  *bx-comp*     T
	  *f-sub*       T
	  *b-sub*       T
	  *fx-sub*      T
	  *bx-sub*      T
          *f-subbar*    NIL
	  *b-subbar*    NIL
	  *fx-subbar*   NIL
	  *bx-subbar*   NIL
	  *f-subcomp*   T
	  *b-subcomp*   T
	  *fx-subcomp*  T
	  *bx-subcomp*  T
          *f2-comp*     T
	  *b2-comp*     T
	  *fx2-comp*    T
	  *bx2-comp*    T
	  *f2-sub*      T
	  *b2-sub*      T
	  *fx2-sub*     T
	  *bx2-sub*     T
	  *f3-comp*     T
	  *b3-comp*     T
	  *fx3-comp*    T
	  *bx3-comp*    T

Training parameters: N = 3 alpha0 = 1.0 c = 1.2 n = 6  *Beamp* = NIL  *Beam-exp* = 0.9

Model parameters before and after training
================================================
key   lex             initial  final    diff 
------------------------------------------------
1     KNOWS             1.0 4.289267  (3.289267)
2     KNOWS             1.0 2.241994  (1.241994)
3     KNOWS             1.0 -.096422  (-1.09642)
4     KNOWS             1.0 -1.14182  (-2.14182)
5     LOVES             1.0 4.577237  (3.577237)
6     LOVES             1.0 -2.63714  (-3.63714)
7     JOHN              1.0 3.729442  (2.729442)
8     JOHN              1.0 2.071611  (1.071611)
9     JOHN              1.0  2.49417  ( 1.49417)
10    JOHN              1.0 -.135959  (-1.13596)
11    MARY              1.0 3.136842  (2.136842)
12    MARY              1.0 2.335226  (1.335226)
13    MARY              1.0 2.863005  (1.863005)
14    MARY              1.0 -.448029  (-1.44803)
15    JOHN              1.0 -1.69447  (-2.69447)
16    JOHN              1.0 -.135959  (-1.13596)
17    MARY              1.0 -1.31433  (-2.31433)
18    MARY              1.0 -.448029  (-1.44803)
================================================