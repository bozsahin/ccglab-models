===================
I am called as: /home/cem/ccglab/bin/ccglab.nohup.sbcl 7000 56 g1 t 2 1.2 1.2 t4.out
            at: Tue Jul 24 17:16:06 EEST 2018
Log goes to   : t4.out
I will call sbcl as: /usr/bin/sbcl --dynamic-space-size 7000
It will call train-nohup-sbcl in /home/cem/ccglab/bin/train-nohup-sbcl.lisp as: (train-nohup-sbcl "g1" 56 t "g1.ind.nohupped.2N.1.2a.1.2c" 2 1.2 1.2)
===================
This is SBCL 1.2.15-1.fc23, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
OOV is reset (OOV errors reported)
All LFs will be shown
*Beamp* = NIL  *Beam-exp* = 0.9
*Beamp* = NIL  *Beam-exp* = 0.9

======================= l o a d i n g =======================================
; loading #P"/home/cem/ccglab-models/noqnoc/g1.ind"

Project [g1] is assumed to consist of
-----------------------------------------------------------------------------
  CCG grammar source : g1.ccg $
    Its token form   : g1.lisptokens $
  Deduction grammar  : g1.ded $ (derived from g1.lisptokens)
  Induction grammar  : g1.ind #
  Supervision source : g1.sup ^
  Model-specific code: g1.lisp ^
   and other model-specific files you may create.
       *CCG-GRAMMAR* : set from g1.ind
  *LEX-RULES-TABLE*  : set from g1.ind
Expected files       : $ for deduction, # for induction, ^ for model development
=============================================================================

Supervision file loaded: g1.sup
Done. use (show-training/save-training) to see/save the results
Evaluation took:
  1.444 seconds of real time
  1.438752 seconds of total run time (1.415879 user, 0.022873 system)
  [ Run times consist of 0.007 seconds GC time, and 1.432 seconds non-GC time. ]
  99.65% CPU
  6 forms interpreted
  3,464,168,025 processor cycles
  96,891,552 bytes consed
  
The rule set used in the experiment:
To change a switch, use (setf <switchname> <value>)
	      where <value> is T (on) or NIL (off)
	  *f-apply*     T
	  *b-apply*     T
	  *f-comp*      T
	  *b-comp*      T
	  *fx-comp*     T
	  *bx-comp*     T
	  *f-sub*       T
	  *b-sub*       T
	  *fx-sub*      T
	  *bx-sub*      T
          *f-subbar*    NIL
	  *b-subbar*    NIL
	  *fx-subbar*   NIL
	  *bx-subbar*   NIL
	  *f-subcomp*   T
	  *b-subcomp*   T
	  *fx-subcomp*  T
	  *bx-subcomp*  T
          *f2-comp*     T
	  *b2-comp*     T
	  *fx2-comp*    T
	  *bx2-comp*    T
	  *f2-sub*      T
	  *b2-sub*      T
	  *fx2-sub*     T
	  *bx2-sub*     T
	  *f3-comp*     T
	  *b3-comp*     T
	  *fx3-comp*    T
	  *bx3-comp*    T

Training parameters: N = 2 alpha0 = 1.2 c = 1.2 n = 6  *Beamp* = NIL  *Beam-exp* = 0.9

Model parameters before and after training
================================================
key   lex             initial  final    diff 
------------------------------------------------
1     KNOWS             1.0 4.111379  (3.111379)
2     KNOWS             1.0 2.048959  (1.048959)
3     KNOWS             1.0 -.037126  (-1.03713)
4     KNOWS             1.0 -.969719  (-1.96972)
5     LOVES             1.0 4.677419  (3.677419)
6     LOVES             1.0 -2.73598  (-3.73598)
7     JOHN              1.0 3.819738  (2.819738)
8     JOHN              1.0 2.054354  (1.054354)
9     JOHN              1.0 2.481334  (1.481334)
10    JOHN              1.0 -.118886  (-1.11889)
11    MARY              1.0 3.047945  (2.047945)
12    MARY              1.0 2.371118  (1.371118)
13    MARY              1.0 2.919959  (1.919959)
14    MARY              1.0 -.497188  (-1.49719)
15    JOHN              1.0 -1.76852  (-2.76852)
16    JOHN              1.0 -.118886  (-1.11889)
17    MARY              1.0 -1.23442  (-2.23442)
18    MARY              1.0 -.497188  (-1.49719)
================================================